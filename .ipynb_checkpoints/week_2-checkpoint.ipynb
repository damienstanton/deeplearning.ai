{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "- Note the differences between the squared loss func one would use in _linear regression_, and why this gets trapped in local minima in the case of binary classification (which is the use case here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{align}\n",
    "\\hat{y} = P(y = 1 | x)\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "where \n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\le\\hat{y}\\le1\\ and\\ x\\in\\mathbb{R}^{n_x}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "parameters:w\\in\\mathbb{R}^{n_x}, b\\in\\mathbb{R}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "output:\\hat{y}=\\sigma(w^{T}+b)\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the sigmoid func above expands to\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\sigma(z)=\\frac{1}{1+e^{-z}}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "this gives the loss func\n",
    "$\n",
    "\\begin{align}\n",
    "\\mathcal{L} = (\\hat{y},y) = (y_{log}\\hat{y} + (1 - y)_{log}(1-\\hat{y})\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "and the cost func\n",
    "$\n",
    "\\begin{align}\n",
    "\\mathcal{J}(w, b) = \\frac{1}{m}\\sum_{i=1}^{m}\\mathcal{L}(\\hat{y}^{(i)},y^{(i)})\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "- the goal is to find a convex func via parameters _w_ and _b_ that minimizes `J(w, b)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rough algorithm:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "Loop:\n",
    "\\quad w := w = \\alpha\\frac{\\delta J(w)}{\\delta w}\n",
    "\\newline\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "\n",
    "where alpha is the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
